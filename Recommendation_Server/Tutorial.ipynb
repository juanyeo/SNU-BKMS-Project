{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Check requirements below before start:\n",
    "requirements: \n",
    "\n",
    "    pip install pandas\n",
    "\n",
    "    pip install torch\n",
    "    \n",
    "    pip install -U sentence_transformers\n",
    "    \n",
    "    pip install googletrans==4.0.0-rc1\n",
    "    \n",
    "## And Just run 'ALL of cells'!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/flask/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "shape:(1, 1024), type: <class 'numpy.ndarray'>\n",
      "shape:torch.Size([1, 1024]), type: <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "model = torch.load('model_large.pth') # 이미 생성된(저장된) 모델을 불러옴.\n",
    "model.eval() ## 이걸 해야 evaluation mode로 진입함. 안 했을 경우 dropout처럼 traning단계에서 확률적으로 변하는 요소들이 반영되어 일관적인 아웃풋이 나오지 않음.\n",
    "\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# model = SentenceTransformer('sentence-transformers/stsb-bert-large')\n",
    "# torch.save(model, 'model_large.pth')\n",
    "\n",
    "# Sentences we want to encode. Example:\n",
    "sentence = ['This framework generates embeddings for each input sentence']\n",
    "\n",
    "print(\"-----------\")\n",
    "# Sentences are encoded by calling model.encode()\n",
    "embedding = model.encode(sentence)\n",
    "print(f\"shape:{embedding.shape}, type: {type(embedding)}\")\n",
    "\n",
    "embedding = model.encode(sentence, convert_to_tensor=True)\n",
    "print(f\"shape:{embedding.shape}, type: {type(embedding)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similaliry between 1 and 2: 0.3606457\n",
      "similaliry between 1 and 3: 0.13557953\n",
      "similaliry between 2 and 3: 0.53019726\n"
     ]
    }
   ],
   "source": [
    "ExampleText1 = 'hello. Im a undergraduate student of computer science. and i have a question for Django framework'\n",
    "ExampleText2 = 'I am trying to follow this tutorial using pip to install a python package locally. Per the tutorial in the bacnet-restful directory when I run pip install wheel I get this error:'\n",
    "ExampleText3 = 'pip is a replacement for easy_install. But should I install pip using easy_install on Windows? Is there a better way?'\n",
    "\n",
    "embedded_vector1 = model.encode([ExampleText1])[0] # 지금은 numpy로 불러오게 되는데, 옵션을 바꾸면 torch로 불러올 수도 있음.\n",
    "embedded_vector2 = model.encode([ExampleText2])[0]\n",
    "embedded_vector3 = model.encode([ExampleText3])[0]\n",
    "\n",
    "# print(torch.norm(embedded_vector1), torch.norm(embedded_vector2), torch.norm(embedded_vector3))\n",
    "def cos_theta(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "print(\"similaliry between 1 and 2:\",cos_theta(embedded_vector1, embedded_vector2))\n",
    "print(\"similaliry between 1 and 3:\",cos_theta(embedded_vector1, embedded_vector3))\n",
    "print(\"similaliry between 2 and 3:\",cos_theta(embedded_vector2, embedded_vector3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load StackOverflow Data & calculate model embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9161, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>69783030</td>\n",
       "      <td>\"ATAL: password authentication failed for user...</td>\n",
       "      <td>I install postgres12 with pgadmin 4 on windows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25370769</td>\n",
       "      <td>\"Backend Error\" when load to BigQuery table</td>\n",
       "      <td>It appears this has been a common issue, it ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>51301363</td>\n",
       "      <td>\"CAST\" function with \"DISTINCT ON\" not changin...</td>\n",
       "      <td>I have two tables parent and child . I need to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>52036705</td>\n",
       "      <td>\"CLUSTER BY expression must be groupable, but ...</td>\n",
       "      <td>I've created a table using the web UI as:&lt;pre&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>67614474</td>\n",
       "      <td>\"CREATE USER PASSWORD\" vs \"CREATE USER WITH PA...</td>\n",
       "      <td>Based on &lt;a href=\"https://www.postgresql.org/d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        id                                              title   \n",
       "0           0  69783030  \"ATAL: password authentication failed for user...  \\\n",
       "1           1  25370769        \"Backend Error\" when load to BigQuery table   \n",
       "2           2  51301363  \"CAST\" function with \"DISTINCT ON\" not changin...   \n",
       "3           3  52036705  \"CLUSTER BY expression must be groupable, but ...   \n",
       "4           4  67614474  \"CREATE USER PASSWORD\" vs \"CREATE USER WITH PA...   \n",
       "\n",
       "                                                body  \n",
       "0  I install postgres12 with pgadmin 4 on windows...  \n",
       "1  It appears this has been a common issue, it ha...  \n",
       "2  I have two tables parent and child . I need to...  \n",
       "3  I've created a table using the web UI as:<pre>...  \n",
       "4  Based on <a href=\"https://www.postgresql.org/d...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOF_dbms.csv is a preprocessed stackoverflow csv file. The preprocess is in 'post_analysis.ipynb'\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('SOF_dbms copy.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os\n",
    "from utils import gen_embedding\n",
    "title = [text for text in df['title']]\n",
    "body = [text for text in df['body']]\n",
    "title_embedding = gen_embedding(title, 'SO_title.pickle')\n",
    "body_embedding = gen_embedding(body, 'SO_body.pickle')\n",
    "\n",
    "print(\"title_shape:\", title_embedding.shape)\n",
    "print(\"body_shape:\", body_embedding.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate Hash function, and calculate the hash value of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SO_title_dataTable.pickle already exist. Loaded fileLoc\n",
      "SO_body_dataTable.pickle already exist. Loaded fileLoc\n"
     ]
    }
   ],
   "source": [
    "import yaml, pickle\n",
    "from mips_ALSH import Mips, HashFt, Hash_Table\n",
    "from utils import gen_DataTable\n",
    "with open('config.yaml', 'r') as f:\n",
    "    params = yaml.load(f, Loader = yaml.FullLoader)\n",
    "\n",
    "hashft_class = HashFt(params)\n",
    "hashft = hashft_class.hash_functions\n",
    "\n",
    "title_Data = gen_DataTable(title_embedding, 'SO_title_dataTable.pickle', hashft)\n",
    "body_Data = gen_DataTable(body_embedding, 'SO_body_dataTable.pickle', hashft)\n",
    "\n",
    "\n",
    "search_engine = Mips(hashft, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------\n",
      "ranking index:  tensor([4580, 5307, 3688, 8225, 6784])\n",
      "\n",
      "tensor(1097)  :  68471431 : How to change .csv file from one folder to another after import to postgreSQL?\n",
      "\n",
      "tensor(1092)  :  60642774 : How to pass a value from Before Trigger to After Trigger\n",
      "\n",
      "tensor(1092)  :  50167517 : Did Postgresq vacuum execute when performing JDBC transaction?\n",
      "\n",
      "tensor(1090)  :  71759507 : Google BigQuery -Revert to the old table view in BigQuery WEB UI?\n",
      "\n",
      "tensor(1090)  :  31993896 : Failure on CSV import into Neo4j 2.2.4 using neo4j-import\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = 'postgresql'\n",
    "ranking, sorted = search_engine.search(text, model.encode([text], convert_to_tensor=True), title_Data, body_Data)\n",
    "print(\"\\n------------------------\")\n",
    "print(\"ranking index: \",ranking)\n",
    "print()\n",
    "for i in range(len(ranking)):\n",
    "    print(sorted[-i-1], \" : \", df.iloc[int(ranking[-i-1]), 1], \":\", df.iloc[int(ranking[-i-1]), 2])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kor2Eng: hello.I want to connect the big query to Diviber, so I have an access problem.When I was only an editor, I had access inquiries, so I created a new project and received both the owner and the role of the editor.\n",
      "How can I connect?\n",
      "Please confirm it.\n",
      "thank you\n",
      "Eng2Eng: hello.I want to connect the big query to Diviber, so I have an access problem.When I was only an editor, I had access inquiries, so I created a new project and received both the owner and the role of the editor.\n",
      "How can I connect?\n",
      "Please confirm it.\n",
      "thank you\n"
     ]
    }
   ],
   "source": [
    "import googletrans\n",
    "translator = googletrans.Translator()\n",
    "\n",
    "Kor_text = '''안녕하세요. 빅쿼리를 디비버에 연결하려는데 엑세스 문제가 있어서 문의 드립니다. 편집자로만 역할을 부여했을 때에도 엑세스 문의가 있어서 새로운 프로젝트를 만들고 소유자와 편집자 역할 모두 부여했는데도 오류코드를 받았습니다.\n",
    "어떻게 해야 연결할 수 있을까요?\n",
    "확인 부탁드립니다ㅠㅠ\n",
    "감사합니다.'''\n",
    "\n",
    "translated_text = translator.translate(Kor_text, dest='en')\n",
    "print(\"Kor2Eng:\", translated_text.text)\n",
    "\n",
    "Eng_text = translated_text.text\n",
    "translated_text = translator.translate(Eng_text, dest='en')\n",
    "print(\"Eng2Eng:\", translated_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------\n",
      "ranking index:  tensor([2966, 5049, 2235, 7860, 8047])\n",
      "\n",
      "38387679 : Convert interval to microseconds as number type in PostgreSQL?\n",
      "\n",
      "15359029 : How to list the train operators that use the second oldest trains (PostgreSQL)\n",
      "\n",
      "50247890 : How to implement PRAGMA EXCEPTION_INIT in Postgres?\n",
      "\n",
      "58289672 : Can I upgrade PostgreSql 10 to PostgreSql 12\n",
      "\n",
      "38406184 : Get each value's difference from overall min value in Postgres\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ranking, sorted = search_engine.search(translated_text.text, model.encode([translated_text.text], convert_to_tensor=True), title_Data, body_Data)\n",
    "print(\"\\n------------------------\")\n",
    "print(\"ranking index: \",ranking)\n",
    "print()\n",
    "for i in range(len(ranking)):\n",
    "    print(df.iloc[int(ranking[-i]), 1], \":\", df.iloc[int(ranking[-i]), 2])\n",
    "    # print(df.iloc[int(ranking[-i]), 3])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2649, 0.9184, 0.9000, 0.6577],\n",
      "        [0.8096, 0.6223, 0.3485, 0.1301],\n",
      "        [0.0627, 0.4490, 0.7404, 0.2592]])\n",
      "tensor([1.0000, 0.7401, 0.6170])\n",
      "tensor([4.0000, 3.8730, 3.8730])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(size = (3, 4))\n",
    "print(a)\n",
    "maxnorm = torch.max(torch.norm(a, dim = 1))\n",
    "\n",
    "print(torch.norm(a/maxnorm, dim = 1))\n",
    "\n",
    "b = a/maxnorm\n",
    "\n",
    "added = torch.Tensor([[0.5-torch.norm(v)**(2**i) for i in range(1, 60+1)] for v in b])\n",
    "        \n",
    "expanded = torch.concat([b, added], dim = 1)\n",
    "\n",
    "print(torch.norm(expanded, dim = 1))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('flask')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f63269090b3a3c689cb2b9efba4c98bfc7a83a37fef10f95977dfe8a0cfd02d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
